{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc4eb51e-2a01-4ab3-bf8f-fa32ff77bf9d",
   "metadata": {},
   "source": [
    "# ANALYSIS ON BREWER\n",
    "In this code, we want to analyse the **geographical distribution** of **breweries** in order to better understand user distribution data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a88a37-7efd-4471-8963-cbfb7d57f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850857f0-a7eb-45c0-b011-e113ad18b7a9",
   "metadata": {},
   "source": [
    "We want to make the code reusable with both datasets, so we will create functions that work on generic entity names, so that we can replicate the analysis while avoiding code redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd9f39d-bad9-451c-9091-bf358f61dbf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'BeerAdvocate/beers.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m breweries_BA \u001b[38;5;241m=\u001b[39m DATA_BA\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbreweries.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m users_BA \u001b[38;5;241m=\u001b[39m DATA_BA\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musers.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m beer_BA \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeer_BA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m breweries_BA \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(breweries_BA)\n\u001b[0;32m      9\u001b[0m users_BA \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(users_BA)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'BeerAdvocate/beers.csv'"
     ]
    }
   ],
   "source": [
    "# LOADING\n",
    "##BEER ADVOCATE DATASET\n",
    "DATA_BA = 'BeerAdvocate/'\n",
    "beer_BA = DATA_BA+\"beers.csv\"\n",
    "breweries_BA = DATA_BA+\"breweries.csv\"\n",
    "users_BA = DATA_BA+\"users.csv\"\n",
    "beer_BA = pd.read_csv(beer_BA)\n",
    "breweries_BA = pd.read_csv(breweries_BA)\n",
    "users_BA = pd.read_csv(users_BA)\n",
    "\n",
    "##RATE BEER DATASET\n",
    "DATA_RB = 'RateBeer/'\n",
    "beer_RB = DATA_RB+\"beers.csv\"\n",
    "breweries_RB = DATA_RB+\"breweries.csv\"\n",
    "users_RB = DATA_RB+\"users.csv\"\n",
    "beer_RB = pd.read_csv(beer_RB)\n",
    "breweries_RB = pd.read_csv(breweries_RB)\n",
    "users_RB = pd.read_csv(users_RB)\n",
    "\n",
    "BA = 'Beer_Advocate'\n",
    "RB = 'Rate_Beer'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfde3d66-c003-45ae-937e-0d3e92e8596e",
   "metadata": {},
   "source": [
    "Analysing the *location* column data, we realised that there was ‘dirty’ data, with HTML elements and URLs inserted as part of the data instead of just clean location names. We therefore decided to cleanse the data of this information, making it all appear in the same format.\n",
    "We also note that again, for the United States we have data for all states within the United States, so we can do an analysis that considers all of the United States as one country and then go into depth on the distribution within the United States.\n",
    "There are also some data that has in *location* column something that starts with 'United State' and then has son caracter lik '| name_of_sites' (e.g. 16302    United States | maprockbottom.com), so we have to filter also this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f61aa7-e115-43af-baca-ee4948b9d8a8",
   "metadata": {},
   "source": [
    "## LOCATION DISTRIBUTION ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf316f07-16ba-4802-8126-49de9fe6235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can find several function that are usefull to extract the information needed\n",
    "\n",
    "# Information of the brewer dataset considered and check on id\n",
    "def dataset_information(breweries, dataset):\n",
    "    print('\\n')\n",
    "    print('########################################################')\n",
    "    print('We are starting analysing dataset', dataset)\n",
    "    print('- Dimension of starting dataset:', breweries.shape)\n",
    "    print('- Columns of dataset: ', breweries.columns)\n",
    "    print('- Are all the id unique? Answer:', breweries['id'].is_unique)\n",
    "    print('- Are there some values that are NaN inside the dataset? Answer:',breweries.isna().any().any())\n",
    "    return None \n",
    "\n",
    "########################## FILTERING BLOCK #############################\n",
    "# This function remove all the line where the brewer has 0 nbr of beer\n",
    "def remove_zero_beer(breweries, dataset):\n",
    "    print('FILTER BLOCK')\n",
    "    print('-- The dimension of starting dataset',dataset,':', breweries.shape[0])\n",
    "    breweries = breweries.loc[~(breweries['nbr_beers']==0)]\n",
    "    print('-- The dimension of filtered dataset',dataset,':', breweries.shape[0])\n",
    "    return breweries\n",
    "    \n",
    "# Cleaning 'location' column from HTML entries\n",
    "def clean_location(location):\n",
    "    # Remove HTML \n",
    "    return re.sub(r'<[^>]+>', '', location).strip()\n",
    "\n",
    "# We clean the data dropping the entities that are not in the desided format\n",
    "def clean_unfitt_data(breweries):\n",
    "    # We create a mask that select all rows where location column starts with 'United States'\n",
    "    mask = breweries['location'].str.startswith('United States')\n",
    "    # We create a mask that consider only the items has 'United States' followed by ', letters' (valid entries) \n",
    "    valid_us_mask = breweries['location'].str.match(r'^United States, [A-Za-z\\s]+$')\n",
    "    # The filtered dataset has all the rows that haven't in location 'United States,..' + the ones about US in valid format\n",
    "    # Mantieni le righe che non sono statunitensi o che sono nel formato corretto\n",
    "    filtered_breweries = breweries[~mask | valid_us_mask]\n",
    "    return filtered_breweries\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "# Extracting data of US from dataset\n",
    "def us_extraction(breweries, dataset):\n",
    "    # We filter the rows when the 'location' column starts with 'United Stater,' \n",
    "    us_breweries = breweries[breweries['location'].str.startswith('United States,')].copy()\n",
    "    # Create a new column 'state' with what is after the ,\n",
    "    us_breweries['state'] = us_breweries['location'].str.split(',').str[1].str.strip()\n",
    "    # Now column 'location' is  useless, so we drop it\n",
    "    us_breweries = us_breweries.drop(columns='location')\n",
    "    us_breweries = us_breweries.rename(columns={'state': 'location'}) #useful for reusing other function\n",
    "    # Give a name to this new dataset (useful for other function)\n",
    "    dataset_name = 'US_'+dataset\n",
    "    return us_breweries, dataset_name\n",
    "\n",
    "# Location distribution analysis: this function group data by location and show:\n",
    "# - how many breweries we have for each country \n",
    "# - how many beers we have per country in total\n",
    "# - mean of beers we have for each contry in every breweries\n",
    "# - std of beers we have for each contry median of beers we have for each contry in every breweries ###\n",
    "# - median of beers we have for each contry in every breweries\n",
    "def loc_distribution(breweries, dataset):\n",
    "    # we uniform the values in column location\n",
    "    breweries['location'] = breweries['location'].apply(clean_location) #filter function\n",
    "    breweries = clean_unfitt_data(breweries) #filter function\n",
    "    print('Dataset:', dataset)\n",
    "    print('- Number of unique \"location\" value in the dataset:', breweries['location'].nunique())\n",
    "    distribution = breweries.groupby('location').agg(\n",
    "        brewery_count=('location', 'size'),\n",
    "        total_beers=('nbr_beers', 'sum'),\n",
    "        mean_beers=('nbr_beers', 'mean'),\n",
    "        std_beers=('nbr_beers', 'std'),\n",
    "        median_beers=('nbr_beers', 'median')).reset_index()\n",
    "    #distribution['mean_beers'] = distribution['mean_beers'].round(2)\n",
    "    #distribution['median_beers'] = distribution['median_beers'].round(2)\n",
    "    return distribution\n",
    "\n",
    "########################## PLOTTING BLOCK #############################\n",
    "# Plotting_dist funtion plot the number of brewer for the best n (=15) \n",
    "# countries. We can visualize the standard deviation and also the mean\n",
    "# number of beer in brewer for each country\n",
    "\n",
    "def plotting_dist(dist, dataset,title, n=15):   \n",
    "    # Select only the first n (to make the plot readable)\n",
    "    dist_bar = dist.sort_values(by='brewery_count', ascending=False).head(n)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    ax.barh(dist_bar['location'], dist_bar['brewery_count'], color='skyblue',label='Number of breweries')\n",
    "    ax.set_title(title, fontsize=15)\n",
    "    ax.set_xlabel('Number of Breweries', fontsize=15)\n",
    "    ax.set_ylabel('Country', fontsize=15)\n",
    "    ax.tick_params(axis='x', labelsize=12)  # Tick dimension\n",
    "    ax.tick_params(axis='y', labelsize=12)  \n",
    "    plt.errorbar(dist_bar['brewery_count'], dist_bar['location'], \n",
    "                 xerr=dist_bar['std_beers'],  # std\n",
    "                 fmt='o', \n",
    "                 color='orange',  \n",
    "                 label='Standard Deviation',  \n",
    "                 capsize=5)  \n",
    "    # Make the table\n",
    "    table_data = dist_bar[['location', 'mean_beers']]\n",
    "    table_data['mean_beers']=round(table_data['mean_beers'],2) # We round the data for a better readability\n",
    "    table = ax.table(cellText=table_data.values,\n",
    "                     colLabels=table_data.columns,\n",
    "                     cellLoc='center',\n",
    "                     loc='right',\n",
    "                     bbox=[1.05, 0, 0.5, 1])  # [left, bottom, width, height]\n",
    "    # Table setting\n",
    "    table_data = table_data.rename(columns={'mean_beers': 'Mean Beers for Brewer','location': 'Location'})\n",
    "    table.auto_set_font_size(False) # Disable automatic font resizing\n",
    "    table.set_fontsize(10)  \n",
    "    table.scale(1, 1.5) \n",
    "    plt.show()\n",
    "\n",
    "def comparing_plot(dist_BA, dist_RB, dist_us_BA, dist_us_RB,n=15):\n",
    "    dist_BA_bar = dist_BA.sort_values(by='brewery_count', ascending=False).head(n)\n",
    "    dist_RB_bar = dist_RB.sort_values(by='brewery_count', ascending=False).head(n)\n",
    "    dist_us_BA_bar = dist_us_BA.sort_values(by='brewery_count', ascending=False).head(n)\n",
    "    dist_us_RB_bar = dist_us_RB.sort_values(by='brewery_count', ascending=False).head(n)\n",
    "    dataset_bar = [dist_BA_bar, dist_RB_bar, dist_us_BA_bar, dist_us_RB_bar]\n",
    "    title = ['BA COMPLETE DATASET', 'RB COMPLETE DATASET','BA US DATASET', 'RB US DATASET']\n",
    "    \n",
    "    i = 0\n",
    "    fig, ax = plt.subplots(2,2, figsize=(20,11),sharex=True)\n",
    "    for i in range(4):\n",
    "        data = dataset_bar[i]\n",
    "        sbplt = ax[i // 2, i % 2]\n",
    "        sbplt.barh(data['location'], data['brewery_count'], color='skyblue',label='Number of breweries')\n",
    "        sbplt.legend()\n",
    "        sbplt.set_title(title[i], fontsize=15)\n",
    "        sbplt.errorbar(data['brewery_count'], data['location'], \n",
    "                     xerr=data['std_beers'],  # std\n",
    "                     fmt='o', \n",
    "                     color='orange',  \n",
    "                     label='Standard Deviation',  \n",
    "                     capsize=5)\n",
    "        sbplt.set_xlabel('Number of Breweries', fontsize=15)\n",
    "        sbplt.set_ylabel('Country', fontsize=15)\n",
    "        sbplt.tick_params(axis='x', labelsize=12)  # Tick dimension\n",
    "        sbplt.tick_params(axis='y', labelsize=12) \n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd5e2a6-d1af-491a-a9e5-9013f9f2ce49",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Informations and processing on dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# BA and RB datasets\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Print general information of starting dataset\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m dataset_information(breweries_BA, \u001b[43mBA\u001b[49m)\n\u001b[0;32m      7\u001b[0m dataset_information(breweries_RB, RB)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Drop brewer with 0 beer and Obtain distribution for full dataset and evaluate statistics for each country\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BA' is not defined"
     ]
    }
   ],
   "source": [
    "## Informations and processing on dataset\n",
    "\n",
    "# BA and RB datasets\n",
    "\n",
    "# Print general information of starting dataset\n",
    "dataset_information(breweries_BA, BA)\n",
    "dataset_information(breweries_RB, RB)\n",
    "\n",
    "# Drop brewer with 0 beer and Obtain distribution for full dataset and evaluate statistics for each country\n",
    "breweries_BA = remove_zero_beer(breweries_BA, BA)\n",
    "dist_BA = loc_distribution(breweries_BA, BA)\n",
    "\n",
    "breweries_RB = remove_zero_beer(breweries_RB, RB)\n",
    "dist_RB = loc_distribution(breweries_RB, RB)\n",
    "\n",
    "# Extract only data of US\n",
    "us_breweries_BA, us_dataset_BA = us_extraction(breweries_BA, BA)\n",
    "us_breweries_RB, us_dataset_RB = us_extraction(breweries_RB, RB)\n",
    "\n",
    "# Print general information of US obtained dataset\n",
    "dataset_information(us_breweries_BA, us_dataset_BA)\n",
    "dataset_information(us_breweries_RB, us_dataset_RB)\n",
    "\n",
    "# Obtain distribution for us dataset and evaluate statistics for each country\n",
    "dist_us_BA = loc_distribution(us_breweries_BA, us_dataset_BA)\n",
    "dist_us_RB = loc_distribution(us_breweries_RB,  us_dataset_RB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed360171-7fd7-4e92-8eb2-af6f27a8b70d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Let's take a look on the top_boundaries of our dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# We can notice that the max number of beer for BA dataset is way highter than in RB\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m max_nbr_beers_BA \u001b[38;5;241m=\u001b[39m breweries_BA[\u001b[43mbreweries_BA\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnbr_beers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mmax\u001b[39m(breweries_BA[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnbr_beers\u001b[39m\u001b[38;5;124m'\u001b[39m])][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnbr_beers\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m      4\u001b[0m counts_BA \u001b[38;5;241m=\u001b[39m breweries_BA[breweries_BA[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnbr_beers\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mmax\u001b[39m(breweries_BA[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnbr_beers\u001b[39m\u001b[38;5;124m'\u001b[39m])][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnbr_beers\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcount()\n\u001b[0;32m      5\u001b[0m max_nbr_beers_RB \u001b[38;5;241m=\u001b[39m breweries_RB[breweries_RB[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnbr_beers\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mmax\u001b[39m(breweries_RB[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnbr_beers\u001b[39m\u001b[38;5;124m'\u001b[39m])][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnbr_beers\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# Let's take a look on the top_boundaries of our dataset\n",
    "# We can notice that the max number of beer for BA dataset is way highter than in RB\n",
    "max_nbr_beers_BA = breweries_BA[breweries_BA['nbr_beers']==max(breweries_BA['nbr_beers'])]['nbr_beers'].max()\n",
    "counts_BA = breweries_BA[breweries_BA['nbr_beers']==max(breweries_BA['nbr_beers'])]['nbr_beers'].count()\n",
    "max_nbr_beers_RB = breweries_RB[breweries_RB['nbr_beers']==max(breweries_RB['nbr_beers'])]['nbr_beers'].max()\n",
    "counts_RB = breweries_RB[breweries_RB['nbr_beers']==max(breweries_RB['nbr_beers'])]['nbr_beers'].count()\n",
    "print('Max number of beer for BA:', max_nbr_beers_BA,'\\nMax number of beer for RB:',max_nbr_beers_RB)\n",
    "print('Max number of beer for BA occur:', counts_BA,'times\\nMax number of beer for RB occur:',counts_RB,'time')\n",
    "#breweries_BA[breweries_BA['nbr_beers']==max(breweries_BA['nbr_beers'])].groupby('location').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bc2732b-4985-4b1c-9d8d-d351ed8ed36c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dist_BA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plotting_dist(\u001b[43mdist_BA\u001b[49m, BA, title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of breweries for each country BA dataset - top n\u001b[39m\u001b[38;5;124m'\u001b[39m,n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dist_BA' is not defined"
     ]
    }
   ],
   "source": [
    "plotting_dist(dist_BA, BA, title = 'Number of breweries for each country BA dataset - top n',n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db93cfd-d35a-47f7-a172-facf1888b891",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_dist(dist_us_BA, us_dataset_BA,title = 'Number of breweries for each country BA US dataset - top n', n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de9fb03-560c-4bc6-94b9-62749bc8cc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_dist(dist_RB, RB, title = 'Number of breweries for each country RB dataset - top n', n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd821925-fbf5-45a6-af0e-1bdaf3414279",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_dist(dist_us_RB, us_dataset_RB, n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639f89d-081c-4ba3-aefd-6091a5c6a9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparing_plot(dist_BA, dist_RB, dist_us_BA, dist_us_RB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa10234f-a30d-4bb1-ac0d-c43224ac0282",
   "metadata": {},
   "source": [
    "## Consideration\n",
    "Here in the end we will add some consideration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
